{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d55b7b-98f5-467a-b77e-0c9a5eea9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape - Rows vs Columns:  (600, 2)\n",
      "    Label                                               Text\n",
      "0       a  refined the groundwork of my character that I ...\n",
      "1       a  the consolation of your father Elizabeth my lo...\n",
      "2       a  and gratitude assisted the development of fili...\n",
      "3       a  a prophetic feeling I felt my heart sink withi...\n",
      "4       a  were now lighted up with indignation now subdu...\n",
      "..    ...                                                ...\n",
      "595     c  with sobs to sing this Beautiful Soup so rich ...\n",
      "596     c  the Mock Turtle yet No said Alice I dont even ...\n",
      "597     c  heavy sobbing of the Mock Turtle Alice was ver...\n",
      "598     c  noticed had powdered hair that curled all over...\n",
      "599     c  on the table Nothing can be clearer than that ...\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "Sample:      Label                                               Text\n",
      "395     b  life saw anyone so much altered as she is sinc...\n",
      "15      a  with a palpable enemy one by one the various k...\n",
      "324     b  herself in bidding farewell the more gentle ad...\n",
      "174     a  painful labour to arrive at once at the summit...\n",
      "142     a  should open a field for the plan of life he ha...\n",
      "Data preparation complete. Output saved to 'gutenberg_partitions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries for the program to run (nltk, random, pandas, requests and re)\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# nltk.download('punkt') ## Download the 'punkt' resource (for the first time)\n",
    "# nltk.download('punkt_tab') ## Download the 'punkt_tab' resource (for the first time)\n",
    "\n",
    "def read_file(url): # This function downloads the text file of a Gutenberg book from the url\n",
    "    response = requests.get(url) # Retrieves the specified book (or text) from the web\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "def clean_book(text): # This function cleans the text of the Gutenberg book\n",
    "    start_data = re.search(r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*\", text, re.IGNORECASE) # Searches text pattern (meta data) at the start of the book\n",
    "    end_data = re.search(r\"\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*\", text, re.IGNORECASE) # Searches text pattern (meta data) at the end of the book\n",
    "    if start_data:\n",
    "        text = text[start_data.end():] # Remove text (in the book) before the end line that matches the pattern in start_data\n",
    "    if end_data:\n",
    "        text = text[:end_data.start()] # Keep text (in the book) before the start line that matches the pattern in end_data\n",
    "\n",
    "    # Remove all non-alphanumeric characters (like punctuations) and subsitute it with ''\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "        \n",
    "def create_partitions(texts, num_partitions): # Creates partitions of the text file of the Gutenberg book\n",
    "    labeled_partitions = []\n",
    "\n",
    "    for label, text in zip('abcdefghijklmnopqrstuvwxyz', texts): # Labels the partitions as a, b, c,..z, one letter per book so that is it unique\n",
    "        text = clean_book(text)    \n",
    "        words = nltk.word_tokenize(text) # Tokenize the text into words\n",
    "\n",
    "        partition_size = 100\n",
    "        partitions = []\n",
    "        \n",
    "        for i in range(num_partitions): # Splits the text into 100 word partitions (200 partitions in total)\n",
    "            start_index = random.randint(0, len(words) - partition_size) # Starts the partitioning at a random start location (or index) in the text of a book\n",
    "            partitions.append(words[start_index:start_index + partition_size])\n",
    "            \n",
    "        labeled_partitions.extend([(label, partition) for partition in partitions])\n",
    "    return labeled_partitions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # URLs for the 3 Gutenberg digital books in text format. These can be changed as needed, so the program works for any Gutenberg digital book\n",
    "    urls = ['https://www.gutenberg.org/files/84/84-0.txt', 'https://www.gutenberg.org/files/1342/1342-0.txt', 'https://www.gutenberg.org/files/11/11-0.txt']\n",
    "    texts = [read_file(url) for url in urls] # Reads each .txt url and stores in 'text'\n",
    "    \n",
    "    partitions = create_partitions(texts, 200) # Creates partitions of the text\n",
    "\n",
    "    # Creates a disctionary and stores labels and corresponding text partitions of 100 words\n",
    "    all_data = {'Label': [], 'Text': []}\n",
    "    for label, partition in partitions:\n",
    "        all_data['Label'].append(label)\n",
    "        all_data['Text'].append(' '.join(partition))\n",
    "    \n",
    "    labeled_partitions_df = pd.DataFrame(all_data) # Converts the dictionary into a dataframe using Pandas and displays aspects of the dataframe below\n",
    "    print(\"Shape - Rows vs Columns: \", labeled_partitions_df.shape)\n",
    "    print(labeled_partitions_df)\n",
    "    print(\"Sample: \", labeled_partitions_df.sample(5)) # Prints a random sample of the dataframe\n",
    "\n",
    "# Saves the labels and corresponding partitions to a CSV file\n",
    "labeled_partitions_df.to_csv(\"gutenberg_partitions.csv\", index=False)\n",
    "print(\"Data preparation complete. Output saved to 'gutenberg_partitions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621b08e-37ae-4f0b-bb3b-330421192e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
